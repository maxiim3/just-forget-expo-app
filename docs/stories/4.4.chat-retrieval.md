# Story 4.4: Chat Retrieval ("Talk to DB")

## Status
Draft

## Story
**As a** user,
**I want** to ask questions in natural language,
**so that** retrieval feels like talking to my notes.

## Acceptance Criteria

1. Chat input in Retrieve view (replaces/augments search)
2. Natural language queries processed by AI
3. AI responds with relevant entries and context
4. Conversation history maintained in session
5. Entries displayed inline with AI responses
6. Can tap entries in chat to view/edit
7. Fallback to semantic search if chat fails

## Tasks / Subtasks

- [ ] Task 1: Create chat UI in Retrieve view (AC: 1, 4)
  - [ ] Replace/augment search input with chat input
  - [ ] Display message bubbles (user + assistant)
  - [ ] Scroll to bottom on new messages
  - [ ] Input field at bottom of screen

- [ ] Task 2: Create chat Edge Function (AC: 2, 3)
  - [ ] Create `supabase/functions/chat-retrieval/index.ts`
  - [ ] Use RAG pattern: retrieve relevant entries + generate response
  - [ ] Include conversation history in context
  - [ ] Return AI response + relevant entry IDs

- [ ] Task 3: Implement RAG retrieval (AC: 2, 3)
  - [ ] Convert user query to embedding
  - [ ] Find relevant entries via similarity search
  - [ ] Pass entries as context to LLM
  - [ ] Generate natural language response

- [ ] Task 4: Display entries in chat (AC: 5, 6)
  - [ ] Show referenced entries as cards in chat
  - [ ] Entries are tappable to open detail
  - [ ] Visual distinction between AI text and entries

- [ ] Task 5: Maintain conversation history (AC: 4)
  - [ ] Store messages in local state
  - [ ] Include recent history in API calls
  - [ ] Clear on session end or manual reset

- [ ] Task 6: Handle errors and fallbacks (AC: 7)
  - [ ] AI unavailable ‚Üí fallback to semantic search
  - [ ] Network error ‚Üí show error, allow retry
  - [ ] No relevant entries ‚Üí helpful response

- [ ] Task 7: Add conversation controls (AC: 4)
  - [ ] Clear conversation button
  - [ ] Optional: save favorite queries
  - [ ] Optional: suggested queries

## Dev Notes

### Chat UI Component
```tsx
// components/retrieve/ChatInterface.tsx
interface Message {
  id: string;
  role: 'user' | 'assistant';
  content: string;
  entries?: Entry[]; // Referenced entries
  timestamp: Date;
}

function ChatInterface() {
  const [messages, setMessages] = useState<Message[]>([]);
  const [input, setInput] = useState('');
  const [isLoading, setIsLoading] = useState(false);

  async function sendMessage() {
    if (!input.trim()) return;

    const userMessage: Message = {
      id: Date.now().toString(),
      role: 'user',
      content: input,
      timestamp: new Date()
    };

    setMessages(prev => [...prev, userMessage]);
    setInput('');
    setIsLoading(true);

    try {
      const { data } = await supabase.functions.invoke('chat-retrieval', {
        body: {
          query: input,
          history: messages.slice(-6), // Last 3 exchanges
          userId: user.id
        }
      });

      const assistantMessage: Message = {
        id: (Date.now() + 1).toString(),
        role: 'assistant',
        content: data.response,
        entries: data.entries,
        timestamp: new Date()
      };

      setMessages(prev => [...prev, assistantMessage]);
    } catch (error) {
      // Handle error
    } finally {
      setIsLoading(false);
    }
  }

  return (
    <View className="flex-1">
      <FlatList
        data={messages}
        renderItem={({ item }) => <ChatMessage message={item} />}
        keyExtractor={(item) => item.id}
        contentContainerStyle={{ padding: 16 }}
      />

      <View className="p-4 border-t border-muted">
        <View className="flex-row">
          <TextInput
            className="flex-1 border-2 border-muted rounded-sketch p-3 font-caveat"
            placeholder="Ask about your thoughts..."
            value={input}
            onChangeText={setInput}
            onSubmitEditing={sendMessage}
          />
          <Pressable onPress={sendMessage} className="ml-2 p-3 bg-accent rounded-sketch">
            <Text>Send</Text>
          </Pressable>
        </View>
      </View>
    </View>
  );
}
```

### Chat Retrieval Edge Function
```typescript
// supabase/functions/chat-retrieval/index.ts
import { serve } from 'https://deno.land/std@0.168.0/http/server.ts';
import OpenAI from 'https://esm.sh/openai@4';
import { createClient } from 'https://esm.sh/@supabase/supabase-js@2';

const openai = new OpenAI({ apiKey: Deno.env.get('OPENAI_API_KEY') });
const supabase = createClient(
  Deno.env.get('SUPABASE_URL')!,
  Deno.env.get('SUPABASE_SERVICE_ROLE_KEY')!
);

serve(async (req) => {
  const { query, history, userId } = await req.json();

  // 1. Generate query embedding
  const embeddingResponse = await openai.embeddings.create({
    model: 'text-embedding-ada-002',
    input: query,
  });
  const queryEmbedding = embeddingResponse.data[0].embedding;

  // 2. Find relevant entries
  const { data: entries } = await supabase.rpc(
    'search_entries_by_similarity',
    {
      query_embedding: queryEmbedding,
      user_id_filter: userId,
      match_threshold: 0.5,
      match_count: 5
    }
  );

  // 3. Build context from entries
  const entriesContext = entries?.map((e, i) =>
    `[Entry ${i + 1}]: ${e.content}`
  ).join('\n\n');

  // 4. Generate response with LLM
  const systemPrompt = `You are a helpful assistant that helps users find and understand their notes.
You have access to the user's entries below. Answer their questions based on these entries.
If no relevant entries exist, say so helpfully.
Keep responses concise and conversational.

USER'S ENTRIES:
${entriesContext || 'No relevant entries found.'}`;

  const messages = [
    { role: 'system' as const, content: systemPrompt },
    ...history.map((m: any) => ({ role: m.role, content: m.content })),
    { role: 'user' as const, content: query }
  ];

  const completion = await openai.chat.completions.create({
    model: 'gpt-4-turbo-preview',
    messages,
    temperature: 0.7,
    max_tokens: 500
  });

  return new Response(JSON.stringify({
    response: completion.choices[0].message.content,
    entries: entries || []
  }));
});
```

### Chat Message Component
```tsx
function ChatMessage({ message }: { message: Message }) {
  const isUser = message.role === 'user';

  return (
    <View className={`mb-4 ${isUser ? 'items-end' : 'items-start'}`}>
      <View className={`max-w-[80%] p-3 rounded-sketch ${
        isUser ? 'bg-accent' : 'bg-surface border-2 border-muted'
      }`}>
        <Text className="font-caveat text-lg">{message.content}</Text>
      </View>

      {/* Referenced entries */}
      {message.entries?.map(entry => (
        <Pressable
          key={entry.id}
          className="mt-2 p-3 bg-surface border-2 border-primary rounded-sketch max-w-[80%]"
          onPress={() => openEntry(entry)}
        >
          <Text className="font-caveat text-sm" numberOfLines={2}>
            üìù {entry.content}
          </Text>
        </Pressable>
      ))}
    </View>
  );
}
```

### Example Conversations
```
User: "What did I need to remember about the meeting?"
Assistant: "You noted that you have a meeting with John about the Q3 budget.
You also mentioned to prepare the quarterly report beforehand."
[Entry cards shown below]

User: "When was that?"
Assistant: "Based on your entry, the meeting was mentioned 3 days ago,
but no specific date was included. Would you like to add a date to it?"

User: "What groceries do I need?"
Assistant: "I found a note about buying milk and eggs. Is there anything
else you'd like to add to that list?"
```

### File Locations
- Edge Function: `supabase/functions/chat-retrieval/index.ts`
- Chat UI: `components/retrieve/ChatInterface.tsx`
- Chat message: `components/retrieve/ChatMessage.tsx`
- Retrieve view: `app/(tabs)/retrieve.tsx`

### Cost Estimation
- GPT-4-turbo: ~$0.01-0.03 per chat exchange
- 50 queries/day ‚âà $0.50-1.50/day
- Consider GPT-3.5-turbo for lower cost (~10x cheaper)

## Testing

### Manual Testing Required
- [ ] Type question ‚Üí AI responds with context
- [ ] Referenced entries shown in chat
- [ ] Tap entry ‚Üí opens detail view
- [ ] Follow-up questions work (history maintained)
- [ ] Clear conversation ‚Üí fresh start
- [ ] No relevant entries ‚Üí helpful response
- [ ] AI error ‚Üí fallback or error message

### Conversation Quality Testing
- [ ] Direct question: "What's on my list?" ‚Üí finds lists
- [ ] Temporal question: "What did I write yesterday?" ‚Üí uses timestamps
- [ ] Vague question: "What was that thing?" ‚Üí asks for clarification
- [ ] Multiple topics ‚Üí finds all relevant entries

### Edge Cases
- [ ] Very long conversation ‚Üí history truncation works
- [ ] Rapid messages ‚Üí handled gracefully
- [ ] Network interruption ‚Üí error handling
- [ ] Empty database ‚Üí helpful onboarding message

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2026-01-12 | 0.1 | Initial draft | John (PM) |

---

## Dev Agent Record

### Agent Model Used
_To be filled by dev agent_

### Debug Log References
_To be filled by dev agent_

### Completion Notes List
_To be filled by dev agent_

### File List
_To be filled by dev agent_

---

## QA Results
_To be filled by QA agent_
